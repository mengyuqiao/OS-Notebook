\documentclass[12pt]{article}

\usepackage{amsmath}

\usepackage{graphicx}

\usepackage{hyperref}

\usepackage{graphicx}
\graphicspath{ {./images/} }

\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=C,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\usepackage[utf8]{inputenc}

\title{Operating System}
\author{Yuqiao Meng}
\date{2021–9–124}

\begin{document}

\maketitle

\newpage
\tableofcontents

\newpage

\section{Overview}

\subsection{What?}

What is an Operating System? What's its reponsibility?

\begin{itemize}
    \item A bunch of software and data residing somewhere in memory.
    \item The most privileged software in a computer. It  can do special things, like write to disk, talk over the network, control memory and CPU usage, etc
    \item Manages all system resources, including CPU, Memory, and I/O devices.
\end{itemize}

\subsection{Why?}
Why do we need an OS?
\begin{itemize}
    \item OS helps program to control hardwares.
    \item OS determines the way programs share resources.
    \item OS protects hardwares and programs from getting attacked.
    \item OS stores files persistently.
\end{itemize}
\includegraphics[width=1.0\textwidth]{WhyDoWeNeedOS.png}

\subsection{How}
\subsubsection{Virtualization}
\begin{itemize}
    \item Definition: OS takes a physical resource (such a sthe processor, or memory, or a disk) and transforms it into a more general, powerful, and easy-to-use virtual form of itself.
    \item Resource Virtualization \begin{itemize}
        \item Many(virtual)-to-one(physical): Memory Virtualization
        \item One-to-many: CPU Virtualization
        \item Many-to-many: Displays
    \end{itemize}
\end{itemize}
\subsubsection{How to invoke OS code?}
\begin{itemize}
    \item System calls: Function calls into the OS, that OS provides these calls to run programs, access memory and devices, and other related actions.
    \item Exceptions: CPU will raise an exception to the OS when the running program do something wrong
    \item Interrupts: Hardwares send interrupts to invoke OS
    \item Kernel Threads: Programs run in the kernel context, executing kernel level functions.
\end{itemize}
\includegraphics[width=0.8\textwidth]{FourWaysToInvokeOS.png}

\subsection{Interface}
\subsubsection{Explaination}
\begin{itemize}
    \item Instruction Set Architecture(ISA): the language CPU understand
    \item User ISA: ISA that any program can execute, it's accessible for all programs, doesn't need the service of operating system
    \item System ISA: ISA that only operating system is allowed to execute.
    \item Application Binary Interface(ABI): the combination of syscalls and User ISA(3, 7), it's the view of the world, seen by programs.
    \item Application Programmers' Interface(API): the combination of libraries and User ISA(2, 7), it's the tools programmer use to write codes.
\end{itemize}
\subsubsection{Interfaces in a Computer System}
\includegraphics[width=0.6\textwidth]{InterfacesInComputerSystem.png}
\begin{itemize}
    \item User ISA: 7
    \item System ISA: 8
    \item Syscalls: 3
    \item Application Binary Interface: 3, 7
    \item Application Programmers' Interface: 2, 7
\end{itemize}

\subsection{History}
\begin{itemize}
    \item First Computer: Atanasoff–Berry computer, or ABC.
    \item First OS: GM-NAA I/O, produced in 1956 by General Motors' Research division for its IBM 704.
    \item First language: Plankalkül, developed by Konrad Zuse for the Z3 between 1943 and 1945.
    \item First programmer: Ada Lovelace
\end{itemize}

\section{Processes}
\subsection{Process}
\subsubsection{What?}
What is a process?
\begin{itemize}
    \item A process is a program in execution. A program is a set of instructions somewhere (like the disk).
    \item Once created, a process continuously does the following: \begin{itemize}
        \item {\bfseries Fetches} an instruction from memory. 
        \item {\bfseries Decodes} it. i.e., figures out which instruction this is. 
        \item {\bfseries Executes} it. it does the thing that it is supposed to do, like add two numbers together, access memory, check a condition, jump to a function, and so forth.
    \end{itemize}
\end{itemize}

\subsubsection{Process versus Program}
How is a process different from a program?
\begin{itemize}
    \item Program: A passive entity stored in the disk, has static code and static data.
    \item Process: Actively executing code and the associated static and dynamic data.
    \item Program is just one component of a process.
    \item There can be multiple process instances of the same program
\end{itemize}

\subsubsection{Constitution}
\begin{itemize}
    \item Memory space
    \item Procedure call stack
    \item Registers and counters
    \item Open files, connections
    \item And more.
\end{itemize}

\subsubsection{Memory layout}
\includegraphics[width=1.0\textwidth]{ProcessMemoryLayout.png}
In this picture, Stack and Heap grow toward each other, that's because every process has a limited amount of space, thus let heap and stack grow toward each other from two direction can make the best use of space.

\subsection{System calls}
\begin{itemize}
    \item fork(): create new process. {\bfseries called once but return twice}. Usage: \begin{itemize}
        \item User runs a program at command line
        \item OS creates a process to provide a service: Check the directory /etc/init.d/ on Linux for scripts that start off different services at boot time.
        \item One process starts another process: For example in servers
    \end{itemize}
    \item exec(): execute a file. {\bfseries replaces the process’ memory with a new program image. All I/O descriptors open before exec stay open after exec}.
    \item wait()/waitpid(): wait for child process.
    \item exit(): terminate a process
\end{itemize}

\subsection{Lifecycle}
\includegraphics[width=1.0\textwidth]{ProcessLifecycle.png}
\begin{itemize}
    \item Ready (runnable; temporarily stopped to let another process run)\begin{itemize}
        \item Process is ready to execute, but not yet executing 
        \item Its waiting in the scheduling queue for the CPU scheduler to pick it up. 
    \end{itemize}
    \item Running:  (actually using the CPU at that instant) 
    \item Blocked (unable to run until some external event happens).\begin{itemize}
        \item Process is waiting (sleeping) for some event to occur. 
        \item Once the event occurs, process will be woken up, and placed on the scheduling queue
    \end{itemize}
\end{itemize}

\begin{enumerate}
    \item Running {$\to$} Blocked: Occurs when the operating system discovers that a process cannot continue right now.
    \item Running {$\to$} Ready: Occurs when the scheduler decides that the running process has run long enough and it is time to let another process have some CPU time.
    \item Ready {$\to$} Running: Occurs when all the other processes have had their fair share and it is time for the first process to get the CPU to run again.
    \item Blocked {$\to$} Ready: Occurs when the external event for which a process was waiting (such as the arrival of some input) happens
\end{enumerate}


\subsection{Special Process}
\begin{itemize}
    \item Orphan process \begin{itemize}
        \item When a parent process dies, child process becomes an orphan process
        \item The init process (pid = 1) becomes the parent of the orphan processes
    \end{itemize}
    \item Zombie process \begin{itemize}
        \item When a child dies, a SIGCHLD signal is sent to the OS, If parent doesn’t wait()on the child, and child exit()s, it becomes a zombie.
        \item Zombies hang around till parent calls wait() or waitpid().
        \item Zombies take up no system resources, it's just a integer status kept in the OS.
        \item Ways to prevent a child process from becoming a zombie: \begin{itemize}
            \item Parent call wait()/waitpid() before child process exit()
            \item Child parent sleep() before exit() until parent process give it a message.
            \item Set act.sa\_flags is SA\_NOCLDWAIT
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Cold-start Penalty}
\subsection{Context Switch}

\section{Inter-Process Communication}
\subsection{Overview}
Inter-Process Communication mechanisms
\begin{itemize}
    \item Pipe: 
    \item Signals: Event notification from one process to another
    \item Shared momery: Common piece of read/write memory, needs authorization for access
    \item Parent-child: Command-line arguments, including waitpid(), wait(), exit()
    \item Reading/modifying common files
    \item Semaphores: Locking and event signaling mechanism between processes
    \item Sockets: Not just across the network, but also between processes
\end{itemize}

\subsection{Pipe}
\subsubsection{Abstraction}
Write to one end, read from another.
\newline
\includegraphics[width=0.8\textwidth]{PipeAbstraction.png}
\subsubsection{Parent-Child Communication Using Pipe}
\includegraphics[width=0.8\textwidth]{ParentChildCommunicationUsingPipe.png}
\subsubsection{File-Descriptor Table}
\begin{itemize}
    \item Each process has a file-descriptor table
    \item One entry for each open file
    \item File includes regular file, stdin, stdout, pipes, etc.
\end{itemize}
\includegraphics[width=0.8\textwidth]{FileDescriptorTable.png}
\subsubsection{Redirect Std to a File}
\begin{lstlisting}
#include <stdio.h>
#include <stdlib.h>
#include <errno.h>
#include <sys/types.h>
#include <unistd.h>

int main()
{
    int fds[2];
    char buf[30];
    pid_t pid1, pid2, pid;
    int status, i;

    /* create a pipe */
    if (pipe(fds) == -1) {
        perror("pipe");
        exit(1);
    }

    /* fork first child */
    if ( (pid1 = fork()) < 0) {
        perror("fork");
        exit(1);
    }

    if ( pid1 == 0 ) {
        close(1);  /* close normal stdout (fd = 1) */
        dup2(fds[1], 1);   /* make stdout same as fds[1] */
        close(fds[0]); /* we don't need the read end -- fds[0] */

        if( execlp("ps", "ps", "-elf", (char *) 0) < 0) {
            perror("Child");
            exit(0);
        }

	/* control never reaches here */
    } 

    /* fork second child */
    if ( (pid2 = fork()) < 0) {
	perror("fork");
	exit(1);
    }

    if ( pid2 == 0 ) {
        close(0);   /* close normal stdin (fd = 0)*/
        dup2(fds[0],0);   /* make stdin same as fds[0] */
        close(fds[1]); /* we don't need the write end -- fds[1]*/

        if( execlp("less", "less", (char *) 0) < 0) {
            perror("Child");
            exit(0);
        }

	/* control never reaches here */
    }

    /* parent doesn't need fds  - MUST close - WHY? */
    /* The reading side is supposed to learn that the writer has finished if it notices an EOF condition. This can only happen if all writing sides are closed.*/
    /* close its reading end (for not wasting FDs and for proper detection of dying reader)*/
    /* close its writing end (in order to be possible to detect the EOF condition).*/
    close(fds[0]); 
    close(fds[1]); 

    /* parent waits for children to complete */
    for( i=0; i<2; i++) {
	pid = wait(&status);
	printf("Parent: Child %d completed with status %d\n", pid, status);
    }

}

\end{lstlisting}
\subsubsection{Handling Chain of Filters Using Pipe}
\emph{command 1 $|$ command 2 $|$ … $|$ command N}
\begin{itemize}
    \item First command? \begin{itemize}
        \item Yes: continue
        \item No: redirect stdin to previous pipe
    \end{itemize}
    \item Last command? \begin{itemize}
        \item Yes: Output
        \item No: \begin{itemize}
            \item create next pipe (if needed)
            \item redirect stdout to next pipe
            \item fork a child for next level of recursion with one command less as input
        \end{itemize}
    \end{itemize}
    \item exec the command for the current level
\end{itemize}
\subsubsection{Byte-stream versus Message}
\begin{itemize}
    \item Byte-Stream abstraction: Pipe \begin{itemize}
        \item Can read and write at arbitrary byte boundaries
        \item Don't need to return explicit bytes of data. \emph{read(fds[0], buf, 6)} \begin{itemize}
            \item read() could reach end of input stream (EOF).
            \item Other endpoint may abruptly close the connection
            \item read() could return on a signal
        \end{itemize}
    \end{itemize}
    \item Message abstraction: Provides explicit message boundaries.
\end{itemize}
\subsubsection{Error Handling}
We must incorporate error handling with every I/O call (actually with any system call)
\begin{itemize}
    \item First check the return value of every read(…)/write(…) system call
    \item Then \begin{itemize}
        \item Wait to read/write more data
        \item Handle any error conditions
    \end{itemize}
\end{itemize}
\includegraphics[width=0.8\textwidth]{PipeErrorHandling.png}

\subsection{Signals}
\subsubsection{Overview}
\begin{itemize}
    \item A notification to a process that an event has occurred, comes from OS or another process
    \item The type of event determined by the type of signal
\end{itemize}
\includegraphics[width=0.6\textwidth]{SignalOverview.png}
\subsubsection{Handling Signals}
\begin{itemize}
    \item Signals can be {\bfseries caught} – i.e. an action (or handler) can be associated with them
    \item Actions can be customized using /emph{sigaction()}, which associates a signal handler with the signal
    \item {\bfseries Default} action for most signals is to \underline{terminate the process}. Except SIGCHLD and SIGURG are ignored by default
    \item Unwanted signals can be {\bfseries ignored}, except SIGKILL or SIGSTOP
\end{itemize}
\subsubsection{SIGCHLD}
\begin{itemize}
    \item Sent to parent when a child process terminates or stops
    \item If act.sa\_handler is SIG\_IGN, SIGCHLD will be ignored (default behavior)
    \item If act.sa\_flags is SA\_NOCLDSTOP, SIGCHLD won't be generated when children stop
    \item If act.sa\_flags is SA\_NOCLDWAIT, children of the calling process will not be transformed into zombies when they terminate
    \item These need to be set in sigaction() before parent calls fork()
\end{itemize}
Usage: handling child's exit without blocking on wait()
\begin{itemize}
    \item Parent could install a signal handler for SIGCHLD
    \item Call wait(…)/waitpid(…)inside the signal handler \begin{lstlisting}
        // sigchild.c
        void handle_sigchld(int signo) {
            pid_t pid;
            int stat;
 
            pid = wait(&stat); //returns without blocking 
            printf("child process exits.");
        }
        \end{lstlisting}
\end{itemize}

\subsection{Shared Memory}
\subsubsection{Overview}
Common chunk of read/write memory among processes.
\newline
\includegraphics[width=0.8\textwidth]{SharedMemoryOverview.png}
\subsubsection{Creating}
\begin{lstlisting}
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/shm.h>

#define SHM_SIZE 1024  /* make it a 1K shared memory segment */

int main(void)
{

       key_t key;
       int shmid;
       char *data;
       int mode;

       /* make the key: */
       /* The ftok() function uses the identity of the file named by the given pathname (which must refer to an existing, accessible file) and the least significant 8 bits of proj_id (which must be nonzero) to generate a key_t type System V IPC key, suitable for use with msgget(2), semget(2), or shmget(2). */
       /* The resulting value is the same for all pathnames that name the same file, when the same value of proj_id is used.  The value returned should be different when the (simultaneously existing) files or the project IDs differ.*/
       if ((key = ftok("test_shm", 'X')) < 0) {
            perror("ftok");
            exit(1);
       }

       /* create the shared memory segment: */
       /* shmget() returns the identifier of the System V shared memory segment associated with the value of the argument key.  It may be used either to obtain the identifier of a previously created shared memory segment (when shmflg is zero and key does not have the value IPC_PRIVATE), or to create a new set.*/
       /* A new shared memory segment, with size equal to the value of size rounded up to a multiple of PAGE_SIZE, is created if key has the value IPC_PRIVATE or key isn't IPC_PRIVATE, no shared memory segment corresponding to key exists, and IPC_CREAT is specified in shmflg.*/
       /* If shmflg specifies both IPC_CREAT and IPC_EXCL and a shared memory segment already exists for key, then shmget() fails with errno set to EEXIST.  (This is analogous to the effect of the combination O_CREAT | O_EXCL for open(2).) */
       /* 0644 means permissions of owner, group and user */
       if ((shmid = shmget(key, SHM_SIZE, 0644 | IPC_CREAT | IPC_EXCL )) < 0) {
            perror("shmget");
            exit(1);
       }

       return(0);
}
\end{lstlisting}
\subsubsection{Attach and Detach}
\begin{lstlisting}
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/shm.h>

#define SHM_SIZE 1024  /* make it a 1K shared memory segment */

int main(int argc, char *argv[])
{

       key_t key;
       int shmid;
       char *data;
       int mode;


       /* make the key: */
       if ((key = ftok("test_shm", 'X')) == -1) {
            perror("ftok");
            exit(1);
       }


       /* connect to the segment. */
	   /* There's no IPC_CREATE. Because if there was one this function would create a new shared memory.*/
       if ((shmid = shmget(key, SHM_SIZE, 0644)) == -1) {
            perror("shmget");
            exit(1);
       }


	    /* attach to the segment to get a pointer to it: */
        /* The shmat() function attaches the shared memory segment associated with the shared memory identifier specified by shmid to the address space of the calling process.*/
        data = shmat(shmid, (void *)0, 0);
        if (data == (char *)(-1)) {
            perror("shmat");
            exit(1);
        }


        /* read or modify the segment, based on the command line: */
        if (argc == 2) {
            printf("writing to segment: \"%s\"\n", argv[1]);
            strncpy(data, argv[1], SHM_SIZE);
        } else
            printf("segment contains: \"%s\"\n", data);


        /* detach from the segment: */
        if (shmdt(data) == -1) {
            perror("shmdt");
            exit(1);
        }

       return(0);
}
\end{lstlisting}
\subsubsection{Deleting}
\begin{lstlisting}
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/shm.h>

#define SHM_SIZE 1024  /* make it a 1K shared memory segment */

int main(void)
{
       key_t key;
       int shmid;
       char *data;
       int mode;

       /* make the key: */
       if ((key = ftok("test_shm", 'X')) == -1) {
            perror("ftok");
            exit(1);
       }

       /* connect to memory segment: */
       if ((shmid = shmget(key, SHM_SIZE, 0644)) == -1) {
            perror("shmget");
            exit(1);
       }

       /* delete he segment */
       /* IPC_RMID: Remove the shared memory identifier specified by shmid from the system and destroy the shared memory segment and shmid_ds data structure associated with it. IPC_RMID can only be executed by a process that has an effective user ID equal to either that of a process with appropriate privileges or to the value of shm_perm.cuid or shm_perm.uid in the shmid_ds data structure associated with shmid.*/
       if( shmctl(shmid, IPC_RMID, NULL) == -1) {
            perror("shmctl");
            exit(1);
       }

       return(0);
}
\end{lstlisting}
\subsubsection{Command}
\begin{itemize}
    \item ipcs: Lists all IPC objects owned by the user 
    \item ipcrm: Removes specific IPC object
\end{itemize}

\section{Threads}
\subsection{Problem}
Want to do multiple tasks Concurrently
\begin{itemize}
    \item Start two processes \begin{itemize}
        \item fork() is expensive
        \item cold-start penalty
    \end{itemize}
\end{itemize}
Processes may need to talk to each other
\begin{itemize}
    \item Two different address spaces, so we need to use IPC \begin{itemize}
        \item kernel transitions are expensive
        \item May need to copy data from a user to kernel to another user
        \item Inter-process Shared memory is a pain to set up
    \end{itemize}
\end{itemize}
\subsection{Solution}
\subsubsection{Event-driven programming}
\begin{itemize}
    \item Make one process do all the tasks 
    \item Busy loop polls for events and executes tasks for each event 
    \item No IPC needed 
    \item {\bfseries Length of the busy loop} determines response latency 
    \item Stateful event responses complicate the code
\end{itemize}
\begin{lstlisting}
while(1) 
{ 
    Check pending events; 
    if (event 1) do task 1; 
    if (event 2) do task 2; 
    // ...
    if (event N) do task N; 
}
\end{lstlisting}
\subsubsection{Threads}
Multiple threads of execution per process
\subsection{Threads}
Shared Resource
\begin{itemize}
    \item virtual address space(code, heap and static data)
    \item Open descriptors (files, sockets etc)
    \item Signals and Signal handlers
\end{itemize}
Non-Shared resources
\begin{itemize}
    \item Program counter
    \item Stack, stack pointer
    \item Registers
    \item Thread ID 
    \item Errno 
    \item Priority
\end{itemize}
\subsubsection{Address space layout}
\includegraphics[width=\textwidth]{ThreadAddressSpace.png}
\subsubsection{Advantages}
\begin{itemize}
    \item Lower inter-thread context switching overhead than processes 
    \item No Inter-process communication \begin{itemize}
        \item Zero data transfer cost between threads 
        \item Only need inter-thread synchronization 
    \end{itemize}
    \item Threads can be pre-empted at any point \begin{itemize}
        \item Long-running threads are OK 
        \item As opposed to event-driven tasks that must be short. 
    \end{itemize}
    \item Threads can exploit parallelism, but it depends…more later 
    \item Threads could block without blocking other threads, but it depends … more later 
\end{itemize}
\subsubsection{Disadvantages}
\begin{itemize}
    \item Shared State! \begin{itemize}
        \item Global variables are shared between threads. 
        \item Accidental data changes can cause errors. 
    \end{itemize}
    \item Threads and signals don’t mix well \begin{itemize}
        \item Common signal handler for all threads in a process 
        \item Which thread to signal? Everybody! 
        \item Royal pain to program correctly. 
    \end{itemize}
    \item Lack of robustness. Crash in one thread will crash the entire process. 
    \item Some library functions may not be thread-safe \begin{itemize}
        \item Library Functions that return pointers to static internal memory. E.g. gethostbyname() 
        \item Less of a problem these days.
    \end{itemize}
\end{itemize}
\subsubsection{Types of Threads}
User-level threads
\begin{itemize}
    \item User-level libraries provide multiple threads,
    \item OS kernel does not recognize user-level threads
    \item Threads execute when the process is scheduled
\end{itemize}
\includegraphics[width=0.6\textwidth]{UserLevelThreads.png}
\newline
Kernel-level threads
\begin{itemize}
    \item OS kernel provides multiple threads per process
    \item Each thread is scheduled independently by the kernel’s CPU scheduler
\end{itemize}
\includegraphics[width=0.6\textwidth]{KernelLevelThreads.png}
\newline
Hybrid Implementations
\newline
\includegraphics[width=0.6\textwidth]{MultiplexingThreads.png}
\newline
Multiplexing user-level threads within each kernel- level threads
\subsubsection{Scheduling}
Local Thread Scheduling
\newline
\includegraphics[width=0.6\textwidth]{LocalThreadScheduling.png}
\begin{itemize}
    \item Next thread is picked from among the threads belonging to the \emph{current process}
    \item Each process gets a timeslice from kernel
    \item Then the timeslice is \emph{divided up} among the threads within the current process 
    \item Local scheduling can be implemented with either Kernel-level Threads or user-level threads
    \item Scheduling decision requires only \emph{local knowledge} of threads within the current process.
\end{itemize}
Global Thread Scheduling
\newline
\includegraphics[width=0.6\textwidth]{GlobalThreadScheduling.png}
\begin{itemize}
    \item Next thread to be scheduled is picked up from \emph{ANY} process in the system. 
    \item Timeslice is allocated at the granularity of threads 
    \item Global scheduling can be implemented only with kernel-level threads: for Picking the next thread requires global knowledge of threads in all processes.
\end{itemize}
\subsubsection{Thread Creation and Termination}
\begin{itemize}
    \item Creation \begin{lstlisting}
        int pthread_create( pthread_t * thread, pthread_attr_t * attr,
        void * (*start_routine)(void *), void * arg);
    \end{lstlisting}
    \item Two ways to perform thread termination \begin{itemize}
        \item Return from initial function \begin{lstlisting}
            void pthread_exit(void * status)
        \end{lstlisting}
    \end{itemize}
    \item Waiting for child thread in parent \begin{itemize}
        \begin{lstlisting}
            pthread_join()
        \end{lstlisting}
        \item equivalent to waitpid
    \end{itemize}
\end{itemize}
\subsubsection{Code}
Example
\begin{lstlisting}
    // shared counter to be incremented by each thread
    int counter = 0;
    main()
    {
        pthread_t tid[N];
        for (i=0;i<N;i++) {
            /*Create a thread in thread_func routine*/
            Pthread_create(&tid[i], NULL, thread_func, NULL);
        }
        for(i=0;i<N;i++) {
            /* wait for child thread */
            Pthread_join(tid[i], NULL);
        }
        void *thread_func(void *arg)
        {
            /* unprotected code race condition */
            counter = counter + 1;
        }
        return NULL; // thread dies upon return
    }
\end{lstlisting}
\subsubsection{pthread Synchronization Operations}
\begin{lstlisting}
    // Mutex operation
    pthread_mutex_init()
    pthread_mutex_lock()
    pthread_mutex_unlock ()
    pthread_mutex_trylock ()

    // Condition variables
    pthread_cond_wait ()
    pthread_cond_signal ()
    pthread_cond_broadcast ()
    pthread_cond_timedwait ()
\end{lstlisting}

\section{Concurrency}
\subsection{Overview}
\begin{itemize}
    \item Sequential: one after another(two tasks executed on one CPU one after another)
    \item Concurrent: "juggling" many things within a time window(two tasks share a single CPU over time)
    \item Parallel: do many things simultaneously(two threads executing on two different CPUs simultaneously)
\end{itemize}
\includegraphics[width=0.8\textwidth]{ConcurrencyOverview.png}
\newline
Concurrent tasks must be either
\begin{itemize}
    \item execute independently
    \item synchronize the shared resource \begin{itemize}
        \item Shared memory
        \item Pipes
        \item Signals
    \end{itemize}
\end{itemize}
\subsection{Critical Section}
\begin{itemize}
    \item Definition: A section of code in a concurrent task that {\bfseries modifies or accesses} a resource shared with another task.
    \item Example: A piece of code that reads from or writes to a shared memory region
\end{itemize}
\subsection{Race Condition and Deadlocks}
\begin{itemize}
    \item Race Condition: Incorrect behavior of a program due to concurrent execution of critical sections by two or more threads
    \item Deadlocks: When two or more processes stop making progress {\bfseries indefinitely} because they are all waiting for each other to do something
\end{itemize}
\subsubsection{Mutual Exclusion}
Don’t allow two or more processes to execute their critical sections concurrently (on the same resource)
\newline
\includegraphics[width=0.8\textwidth]{MutualExclusionOverview.png}
\subsubsection{Conditions for correct mutual exclusion}
\begin{itemize}
    \item No two processes are simultaneously in the critical section 
    \item No assumptions are made about speeds or numbers of CPUs 
    \item No process must wait forever to enter its critical section. Waiting forever indicates a \emph{deadlock}
    \item No process running outside its critical region may block another process running in the critical section
\end{itemize}
The first two conditions are  enforced by the operating system’s implementation of locks, but the other two conditions have to be ensured by the programmer using the locks.
\subsubsection{Typs of Locks}
\begin{itemize}
    \item Blocking locks \begin{itemize}
        \item Give up CPU till lock becomes available \begin{lstlisting}
while(lock unavailable)
    yield CPU to others; // or block till lock available        
return success;
            \end{lstlisting}
        \item Usage: \begin{lstlisting}
Lock(resource); // Claim a shared resource
Execute Critical Section;//access or modify the shared resource
Unlock(resource); // unclaim shared resource
        \end{lstlisting}
        \item Advantage: Simple to use. Locking always succeeds…ultimately
        \item Disadvantage: Blocking duration may be indefinite \begin{itemize}
            \item Process is moved out of “Running” state to “Blocked” state, and return to running will cost much resource
            \item Delay in getting back to running state if lock becomes available soon after blocking
        \end{itemize}
    \end{itemize}
    \item Non-blocking locks \begin{itemize}
        \item Don’t block if lock is unavailable \begin{lstlisting}
if(lock unavailable)
    return failure;
else
    return success
        \end{lstlisting}
        \item Usage \begin{lstlisting}
if(TryLock(resource) == success)
    Execute Critical Section;
    Unlock(resource);
else
    Do something else; // plan B
        \end{lstlisting}
        \item Advantage: No unbounded blocking
        \item Disadvantage: Need a “plan B” to handle locking failure
    \end{itemize}
    \item Spin locks \begin{itemize}
        \item Don’t block. Instead, constantly poll the lock for availability \begin{lstlisting}
while (lock is unavailable) 
continue; // try again
return success;
        \end{lstlisting}
        \item Usage: Just like blocking locks \begin{lstlisting}
SpinLock(resource);
Execute Critical Section;
SpinUnlock(resource);
        \end{lstlisting}
        \item Advantage: Very efficient with short critical sections, if you expect a lock to be released quickly
        \item Disadvantage: \begin{itemize}
            \item Doesn’t yield the CPU and wastes CPU cycles, Bad if critical sections are long: P1 is in the ready queue, but P2 is doing spin with CPU until scheduler interrupts it and give CPU to P1
            \item Efficient only if machine has multiple CPUs
        \end{itemize}
    \end{itemize}
\end{itemize}
\subsubsection{Best practices for locking}
\begin{itemize}
    \item {\bfseries Associate locks with shared resources, NOT code.}
    \item {\bfseries Guard each shared resource by a separate lock.}
    \item {\bfseries OS cannot enforce these properties}
\end{itemize}
\subsubsection{Deadlock Solution}
Deadlock can only be prevented, once it happens, programmers can't solve it by killing the process or enforcing the process to give up the lock.
\newline
Right Solution: Lock Ordering
\begin{itemize}
    \item Sort the locks in a fixed order (say L1 followed by L2) 
    \item Always acquire subset of locks in the sorted order.
\end{itemize}
\subsubsection{Priority Inversion}
Conditions
\begin{itemize}
    \item static priority system
    \item synchronization between processes
\end{itemize}
Example
\begin{itemize}
    \item Definition: \begin{itemize}
        \item Ph – High priority 
        \item Pm – Medium priority 
        \item Pl – Low priority
    \end{itemize}
    \item Procedure \begin{itemize}
        \item Pl acquires a lock L 
        \item Pl starts executing critical section 
        \item Ph tries to acquire lock L and blocks 
        \item Pm becomes “ready” and preempts Pl from the CPU. 
        \item Pl might never exit critical section if Pm keeps preempting Pl
        \item So Ph might never enter critical section
    \end{itemize}
    \item Problem: A high priority process Ph is blocked waiting for a low priority process Pl, Pl cannot proceed because a medium priority process Pm is executing
    \item Solution: Priority Inheritance \begin{itemize}
        \item Temporarily increase the priority of Pl to HIGH PRIORITY 
        \item Pl will be scheduled and will exit critical section quickly 
        \item Then Ph can execute
    \end{itemize}
\end{itemize}

\section{Semaphores, Condition Variables, Producer Consumer Problem}
\subsection{Semaphores}
\subsubsection{Definition}
Can be seen as a non-negative integer
\begin{itemize}
    \item Semaphore is a fundamental synchronization primitive used for \begin{itemize}
        \item Locking around critical regions 
        \item Inter-process synchronization
    \end{itemize}
    \item A semaphore “sem” is a special integer on which only two operations can be performed \begin{itemize}
        \item DOWN(sem)
        \item UP(sem)
    \end{itemize}
\end{itemize}
\subsubsection{DOWN(sem) Operation}
\begin{itemize}
    \item If (sem \textgreater \ 0) then \begin{itemize}
        \item Decrements sem by 1 
        \item The caller continues executing. 
        \item This is a {\bfseries successful} down operation.
    \end{itemize}
    \item If (sem == 0) then \begin{itemize}
        \item Block the caller 
        \item The caller blocks until another process calls an UP. 
        \item The blocked process wakes up and tries DOWN again. 
        \item If it succeeds, then it moves to {\bfseries ready} state 
        \item Otherwise it is blocked again till someone calls UP. 
        \item And so on
    \end{itemize}
\end{itemize}
\subsubsection{UP(sem) Operation}
\begin{itemize}
    \item This operation increments the semaphore sem by 1. 
    \item If the original value of the semaphore was 0, then UP operation wakes up {\bfseries all processes} that were sleeping on the DOWN(sem) operation. 
    \item All woken up processes compete to perform DOWN(sem) again. Only one of them succeeds and the rest are blocked again.
\end{itemize}
\subsubsection{Mutex}
A simply binary semaphore
\begin{itemize}
    \item Used as a LOCK around critical sections
    \item Locking a mutex means calling Down(mutex)
    \item Unlocking a semaphore means calling UP(mutex)
\end{itemize}
\subsection{Producer-Consumer Problem}
\subsubsection{Definition}
\includegraphics[width=0.8\textwidth]{Producer-ConsumerProblem.png}
\begin{itemize}
    \item Producers and consumers run in concurrent processes.
    \item Producers produce data and consumers consume data.
    \item Producer informs consumers when data is available
    \item Consumer informs producers when a buffer is empty.
    \item Two types of synchronization needed \begin{itemize}
        \item Locking the buffer to prevent concurrent modification
        \item Informing the other side that data/buffer is available
    \end{itemize}
\end{itemize}
\subsubsection{Solution}
\begin{lstlisting}
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer(void){
    int item;
    while(true){
        item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer(void){
    int item;
    while(true){
        down(&full);
        down(&mutex);
        item = remove_item();
        up(&mutex);
        up(&empty);
        consume_item(item);
    }
}
\end{lstlisting}

\end{document}